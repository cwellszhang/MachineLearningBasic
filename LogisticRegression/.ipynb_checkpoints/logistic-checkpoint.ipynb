{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归\n",
    "====\n",
    "基本原理：《实战》这本书上是这么讲的，“回归”就是用一条直线对一堆数据点进行拟合，这个拟合过程就称为“回归”。利用Logistic回归进行分类的主要思想是，根据现有数据对分类边界线建立回归公式，以此进行分类。\n",
    "\n",
    "![](pic_lr1.png)\n",
    "\n",
    "圆（蓝色）和叉（红色）是两类数据点，我们需要找到一个决策边界将其划分开，如图所示的边界形式显然是线性的形式，如图中所描述的：\n",
    "$$h_\\theta(x) = g(\\theta_0+\\theta_1x_1+\\theta_2x_2)$$\n",
    "\n",
    "这里，括号里的就是决策边界的表达式，我们找一个函数g，将表达式结果作为输入，生成一个预测函数hθ(x).这里我们使用Sigmoid函数\n",
    "\n",
    "\n",
    "$$ g(z) = {1\\over{1+e^{-z}}} $$\n",
    "$$ h_\\theta(x)=g(\\theta^Tx) $$\n",
    "\n",
    "然而有时候，决策边界用一维直线无法区分，也就是这里的θ参数个数是变数，比如下面这堆数据\n",
    "\n",
    "![](pic_lr2.png)\n",
    "\n",
    "这是一种非线性的决策边界。\n",
    "\n",
    "可以看到这里，将x1,x2参数全部平方处理，找得一个圆形边界。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式推导\n",
    "====\n",
    "讲到这里，我们可以把边界形式做如下推广：\n",
    "$$\\theta_0 + \\theta_1x_1+\\theta_2x_2+...+\\theta_nx_n=\\sum_{i=0}^n\\theta_ix_i=\\theta^Tx$$ \n",
    "\n",
    "将其输入到sigmoid函数去判断其所属类别，就有了我们的预测函数，记为：\n",
    "$$h_\\theta(x) = sigmoid(\\theta^Tx)= {1 \\over{1+e^{-\\theta^Tx}}}$$\n",
    "\n",
    "根据sigmoid图像，这个预测函数输出值大于0，那么代表x（数据点）所属类别为1，否则是0（对于二分类问题）。\n",
    "\n",
    "\n",
    "* 我们先来看看现在我们已经知道什么：\n",
    "\n",
    "　　　　　　1、一堆数据点+它们的类别（2类）\n",
    "\n",
    "　　　　　　2、它们的概率分布hθ(x)：虽然目前θ仍然是未知参数\n",
    "      \n",
    "\n",
    "我们的目标是求出未知参数，使得每个样本数据点属于它当前所标记的类别的概率最大。\n",
    "\n",
    "于是就引出了Fisher的极大似然估计。\n",
    "\n",
    "这里就不讲极大似然估计的具体概念和公式推导了，不过还是用个例子来形象的说明极大似然估计的作用吧：\n",
    "\n",
    "　　　　　　　　一个猎人和一个学生一起走在山路上，突然从山间跑出一只兔子，啪一声枪响，兔子倒地而亡。问：谁最有可能杀死了兔子？\n",
    "\n",
    "　　答案显而易见：猎人。那么这里，猎人就是那个参数θ。极大似然估计的目标就是预测出待估参数，使得样本事件发生的概率最大。\n",
    "  \n",
    "----\n",
    "接下来就是估计所需要的数学推导了。\n",
    "\n",
    "对于一个连续性的分布，我们需要它的概率密度函数，在本例中，其实就是那个sigmoid函数（取值范围0-1刚好表示的是发生概率），我们重新写在这里：\n",
    "$$P(y=1|x;\\theta)=h_\\theta(x)$$\n",
    "$$P(y=0|x;\\theta)=1-h_\\theta(x)$$\n",
    "\n",
    "把这两个式子写在一起：\n",
    "$$P(y|x;\\theta) = (h_\\theta(x)^y)(1-h_\\theta(x))^{1-y}$$\n",
    "\n",
    "可以验证一下，当y=1或者y=0的时候，上式分别满足上上式。对每个样本数据点，满足上式，所以对于群体，我们接下来继续。\n",
    "\n",
    "根据极大似然估计的求解步骤，取似然函数：\n",
    "$$L(\\theta)=\\prod_{i=1}^m(h_\\theta(x)^y)(1-h_\\theta(x))^{1-y}$$\n",
    "要求L(θ)的最大值对应的θ参数。其中m是样本数据点的个数\n",
    "\n",
    "连乘不容易求解，同时又容易造成下溢出。这里由于x和ln(x)单调性相同，两边取对数\n",
    "\n",
    "$$J(\\theta)=logL(\\theta) = \\sum_{i=1}^m( y^{(i)}logh_\\theta(x^{i})\n",
    "+(1-y^{(i)}log(1-h_\\theta(x^{(i)})))$$\n",
    "\n",
    "这个就是Andrew给的那个J(θ)了，唯一的区别就是，Andrew在前面乘了一个负系数，使得这里求最大值变成了最小值，从而可以使用梯度下降算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(direction):\n",
    "    trainfileList=listdir(direction)\n",
    "    m=len(trainfileList)\n",
    "    dataArray= zeros((m,1024))\n",
    "    labelArray= zeros((m,1))\n",
    "    for i in range(m):\n",
    "        returnArray=zeros((1,1024))  #每个txt文件形成的特征向量\n",
    "        filename=trainfileList[i]\n",
    "        fr=open('%s/%s' %(direction,filename))\n",
    "        for j in range(32):\n",
    "            lineStr=fr.readline()\n",
    "            for k in range(32):\n",
    "                returnArray[0,32*j+k]=int(lineStr[k])\n",
    "        dataArray[i,:]=returnArray   #存储特征向量\n",
    "    \n",
    "        filename0=filename.split('.')[0]\n",
    "        label=filename0.split('_')[0]\n",
    "        labelArray[i]=int(label)     #存储类别\n",
    "    return dataArray,labelArray\n",
    "# loadData函数\n",
    "# 实现的功能是从文件夹中读取所有文件，并将其转化为矩阵返回\n",
    "# 如调用loadData('train')，则函数会读取所有的txt文件（'0_0.txt'一直到'1_150.txt'）\n",
    "# 并将每个txt文件里的32*32个数字转化为1*1024的矩阵，最终返回大小是m*1024的矩阵\n",
    "# 同时返回每个txt文件对应的数字，0或1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "梯度下降法\n",
    "====\n",
    "\n",
    "所谓梯度，就是梯度就是函数变化最快的方向，我们一开始现将参数$\\theta$全设为1，然后在算法迭代的每一步里计算梯度，沿着梯度方向移动，以此来改变参数$\\theta$,直到$\\theta$的拟合效果达到要求值或者迭代步数达到设定值。$\\theta$的更新公式：\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha {\\partial \\over \\partial\\theta_j}J(\\theta),j=(0,1,...,n) $$ \n",
    "\n",
    "可以看到，这是一个θ值不断迭代的过程，其中α是学习速率，就是θ的移动“步幅”，后面的偏导数就是梯度，可以理解为cost函数在θ当前位置对于j位置特征的下降速度。\n",
    "\n",
    "对于二维空间，梯度可以理解为函数图像的切线斜率。即：特征是一维的\n",
    "\n",
    "对于多维特征，cost函数的图像就应该是这样的，下面举个例子：\n",
    "\n",
    "![](pic_lr3.png)\n",
    "\n",
    "这是一个二维特征的cost函数的图像，这个时候，梯度有无限多个，我们不能只说cost函数的梯度，应该说，cost函数在某个方向上的梯度。例如，cost函数在θ0方向上，在(θ0=m,θ1=n)上的梯度就是cost函数与θ1=n这个平面的交线在（m,n）处的斜率。\n",
    "\n",
    "上面的描述比较抽象，简单说来，假设图像就是一个小山坡（有点像吧），你站在图像的（m,n）点处，朝θ0的方向看过去，看到的“山坡”的“坡度”就是上面所说的梯度了。\n",
    "\n",
    "这个迭代过程，用形象化的语言描述，就是：\n",
    "\n",
    "　　我站在山坡上，找到一个初始点θj,每次我沿着某一个方向走α这么长的路，由于总是朝着梯度的方向走，我总会走到山坡底（也就是cost函数的极小值）。\n",
    "  \n",
    "  然而，这样的“盆地”可能有多个，我们不同的走法，可能会走到不同的山底，如图：\n",
    "\n",
    "![](pic_lr4.png)\n",
    "\n",
    "这里的两条路线分别走向不同的山谷，这就说明：梯度下降算法只能求出一个局部最小值，不一定是全局最小值，但这不影响它是一个好的方法。\n",
    "\n",
    "这样，θ的迭代过程就讲清楚了。接下来说一下迭代的终止条件。\n",
    "\n",
    "迭代肯定不是无限下去的，我们不妨想一下：当我们走到了山谷，再想往某个方向走的时候，发现都不能再往下走了，那么我们的旅行就终止了。\n",
    "  \n",
    "同样，当θ迭代了n次后（就如图2的黑线一样），发现接下来走α这么长的路，下降的高度很小很小（临界值），或者不再下降，甚至反而往上走了，所以我们的迭代终止条件就是cost函数的减少值小于某个值。\n",
    "\n",
    "我们再来回顾一下迭代公式：其中α是经验设定，称之为learning rate，初始值也是随机选定，那么后面的那个梯度呢？\n",
    "\n",
    "梯度就是cost函数对于特征向量某一维的偏导数。我们来看看这个怎么推导和简化。\n",
    "\n",
    "$\\alpha$是步长,一系列推导之后:\n",
    "$$\\theta_j := \\theta_j - \\alpha \\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} $$\n",
    "\n",
    "公式推导用的也就是偏导数的求解等少量数学公式，关键是体会局部最优的思想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(inX):\n",
    "    return 1.0/(1+exp(-inX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用梯度下降法计算得到回归系数\n",
    "#alpha:步长，maxCycles:迭代次数，可以调整\n",
    "def gradAscent(dataArray,labelArray,alpha,maxCycles):\n",
    "    dataMat=mat(dataArray)        #size:m*n\n",
    "    labelMat=mat(labelArray)      #size:m*1\n",
    "    m,n=shape(dataMat)\n",
    "    weigh=ones((n,1)) \n",
    "    for i in range(maxCycles):\n",
    "        h=sigmoid(dataMat*weigh)\n",
    "        error=labelMat-h    #size:m*1\n",
    "        weigh=weigh+alpha*dataMat.transpose()*error\n",
    "    return weigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfy(testdir,weigh):\n",
    "    dataArray,labelArray=loadData(testdir)\n",
    "    dataMat=mat(dataArray)\n",
    "    labelMat=mat(labelArray)\n",
    "    h=sigmoid(dataMat*weigh)  #size:m*1\n",
    "    m=len(h)\n",
    "    error=0.0\n",
    "    for i in range(m):\n",
    "        if int(h[i])>0.5:\n",
    "            print (int(labelMat[i]),'is classfied as: 1')\n",
    "            if int(labelMat[i])!=1:\n",
    "                error+=1\n",
    "                print ('error')\n",
    "        else:\n",
    "            print (int(labelMat[i]),'is classfied as: 0')\n",
    "            if int(labelMat[i])!=0:\n",
    "                error+=1\n",
    "                print ('error')\n",
    "    print('error rate is:','%.4f' %(error/m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitRecognition(trainDir,testDir,alpha=0.07,maxCycles=10):\n",
    "    data,label=loadData(trainDir)\n",
    "    weigh=gradAscent(data,label,alpha,maxCycles)\n",
    "    classfy(testDir,weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 1\n",
      "error\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "0 is classfied as: 0\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "1 is classfied as: 1\n",
      "error rate is: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "digitRecognition('train','test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
